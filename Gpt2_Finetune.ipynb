{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNdJTI8k8+H9/FeesBLmjZK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahul21chavan/Finetuning_Model/blob/main/Gpt2_Finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCIwAB6Tm0US",
        "outputId": "3b157e58-34e0-43f6-8655-75f81e2793b1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.31.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (18.1.8)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Define a simple dataset for training\n",
        "class SimpleDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_length=128):\n",
        "        tokenizer.pad_token = tokenizer.eos_token  # Set padding token to EOS\n",
        "        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=max_length)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}"
      ],
      "metadata": {
        "id": "9JsERT3Hm3GR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained GPT-2 model and tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "_rQExEOtnCy5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uadQtyBnnpNA",
        "outputId": "2a9c51b5-be99-4b0b-a93f-7de3249d1639"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "z_a1HyS2nrAu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data = [\n",
        "    (\"proc means data=mydata; run;\", \"mydata.describe().show()\"),\n",
        "    (\"data newdata; set olddata; if age>30; run;\", \"newdata = olddata.filter(olddata['age'] > 30)\"),\n",
        "    (\"proc freq data=mydata; tables gender; run;\", \"mydata.groupBy('gender').count().show()\"),\n",
        "    (\"proc sort data=mydata out=sorted_data; by age; run;\", \"sorted_data = mydata.orderBy('age')\"),\n",
        "    (\"proc print data=mydata; run;\", \"mydata.show()\"),\n",
        "    (\"data mydata; infile 'mydata.csv' dsd; input id name age; run;\", \"mydata = spark.read.csv('mydata.csv', header=True, inferSchema=True)\"),\n",
        "    (\"proc import datafile='mydata.csv' out=mydata dbms=csv replace; run;\", \"mydata = spark.read.csv('mydata.csv', header=True, inferSchema=True)\"),\n",
        "    (\"proc export data=mydata outfile='mydata.csv' dbms=csv replace; run;\", \"mydata.write.csv('mydata.csv', header=True, mode='overwrite')\"),\n",
        "    (\"proc sql; create table newdata as select * from olddata where age>30; quit;\", \"newdata = spark.sql('SELECT * FROM olddata WHERE age > 30')\"),\n",
        "    (\"proc transpose data=mydata out=transposed_data; var age; by id; run;\", \"transposed_data = mydata.groupBy('id').pivot('age').agg({'age': 'first'})\"),\n",
        "    (\"proc univariate data=mydata; var age; run;\", \"mydata.select('age').summary().show()\"),\n",
        "    (\"proc corr data=mydata; var age height; run;\", \"mydata.corr('age', 'height')\"),\n",
        "    (\"proc reg data=mydata; model y=x; run;\", \"from pyspark.ml.regression import LinearRegression; lr = LinearRegression(featuresCol='x', labelCol='y'); model = lr.fit(mydata)\"),\n",
        "    (\"proc logistic data=mydata; model y=x; run;\", \"from pyspark.ml.classification import LogisticRegression; lr = LogisticRegression(featuresCol='x', labelCol='y'); model = lr.fit(mydata)\"),\n",
        "    (\"proc gplot data=mydata; plot y*x; run;\", \"import matplotlib.pyplot as plt; plt.plot(mydata.select('x').collect(), mydata.select('y').collect())\"),\n",
        "    (\"data mydata; length name $20; input id name age; run;\", \"from pyspark.sql.types import StructType, StructField, IntegerType, StringType; schema = StructType([StructField('id', IntegerType()), StructField('name', StringType()), StructField('age', IntegerType())]); mydata = spark.createDataFrame([], schema)\"),\n",
        "    (\"proc format; value agefmt 1-10='Child' 11-18='Teenager' 19-high='Adult'; run;\", \"from pyspark.sql.functions import when; mydata = mydata.withColumn('age_group', when(mydata['age'].between(1, 10), 'Child').when(mydata['age'].between(11, 18), 'Teenager').otherwise('Adult'))\"),\n",
        "    (\"proc summary data=mydata nway; class gender; var age; output out=summary_data mean=mean_age; run;\", \"summary_data = mydata.groupBy('gender').agg({'age': 'mean'})\"),\n",
        "    (\"proc means data=mydata noprint; var age; output out=stats mean=mean_age; run;\", \"stats = mydata.agg({'age': 'mean'})\"),\n",
        "    (\"data mydata; set olddata; rename oldname=newname; run;\", \"mydata = olddata.withColumnRenamed('oldname', 'newname')\"),\n",
        "    (\"data mydata; set olddata (keep=id name); run;\", \"mydata = olddata.select('id', 'name')\"),\n",
        "    (\"data mydata; set olddata (drop=age); run;\", \"mydata = olddata.drop('age')\"),\n",
        "    (\"proc append base=basedata data=newdata; run;\", \"basedata = basedata.union(newdata)\"),\n",
        "    (\"proc merge base=basedata data=newdata; by id; run;\", \"basedata = basedata.join(newdata, 'id')\"),\n",
        "    (\"data mydata; merge basedata newdata; by id; run;\", \"mydata = basedata.join(newdata, 'id')\"),\n",
        "    (\"proc sql; select * from mydata where age between 20 and 30; quit;\", \"mydata.filter(mydata['age'].between(20, 30)).show()\"),\n",
        "    (\"proc sql; select id, name, sum(sales) as total_sales from mydata group by id, name; quit;\", \"mydata.groupBy('id', 'name').agg({'sales': 'sum'}).withColumnRenamed('sum(sales)', 'total_sales').show()\"),\n",
        "    (\"proc sql; select * from mydata order by age desc; quit;\", \"mydata.orderBy(mydata['age'].desc()).show()\"),\n",
        "    (\"data mydata; set olddata; if age=. then age=0; run;\", \"mydata = olddata.fillna(0, subset=['age'])\"),\n",
        "    (\"data mydata; set olddata; length newvar $10; newvar='New Value'; run;\", \"mydata = olddata.withColumn('newvar', lit('New Value'))\"),\n",
        "    (\"proc datasets library=work; delete olddata; run; quit;\", \"olddata.unpersist()\"),\n",
        "    (\"data mydata; set olddata; by group; if first.group then count=1; else count+1; run;\", \"from pyspark.sql.window import Window; from pyspark.sql.functions import row_number; w = Window.partitionBy('group').orderBy('some_column'); mydata = olddata.withColumn('count', row_number().over(w))\"),\n",
        "    (\"proc rank data=mydata out=ranked_data groups=10; var age; ranks rank; run;\", \"from pyspark.ml.feature import QuantileDiscretizer; qd = QuantileDiscretizer(numBuckets=10, inputCol='age', outputCol='rank'); ranked_data = qd.fit(mydata).transform(mydata)\"),\n",
        "    (\"proc freq data=mydata; tables gender*age / chisq; run;\", \"from pyspark.ml.stat import ChiSquareTest; r = ChiSquareTest.test(mydata, 'age', 'gender').head(); print('pValues: ' + str(r.pValues))\"),\n",
        "    (\"proc tabulate data=mydata; class gender; var age; table gender, age*mean; run;\", \"mydata.groupBy('gender').pivot('age').agg({'age': 'mean'}).show()\"),\n",
        "    (\"proc gchart data=mydata; vbar age / type=freq; run;\", \"mydata.groupBy('age').count().toPandas().plot(kind='bar', x='age', y='count')\"),\n",
        "    (\"proc gchart data=mydata; pie gender; run;\", \"mydata.groupBy('gender').count().toPandas().plot(kind='pie', y='count', labels=mydata.groupBy('gender').count().toPandas()['gender'])\"),\n",
        "    (\"proc corr data=mydata; var age height weight; with gender; run;\", \"mydata.groupBy('gender').agg(corr('age', 'height').alias('age_height_corr'), corr('age', 'weight').alias('age_weight_corr'), corr('height', 'weight').alias('height_weight_corr')).show()\"),\n",
        "    (\"proc sql; create index idx_id on mydata(id); quit;\", \"mydata.createOrReplaceTempView('mydata'); spark.sql('CREATE INDEX idx_id ON mydata(id)')\"),\n",
        "    (\"proc sql; drop index idx_id on mydata; quit;\", \"mydata.createOrReplaceTempView('mydata'); spark.sql('DROP INDEX idx_id ON mydata')\"),\n",
        "    (\"data mydata; set olddata; where age>30 and gender='Male'; run;\", \"mydata = olddata.filter((olddata['age'] > 30) & (olddata['gender'] == 'Male'))\"),\n",
        "    (\"data mydata; set olddata; where age in (20, 30, 40); run;\", \"mydata = olddata.filter(olddata['age'].isin([20, 30, 40]))\"),\n",
        "    (\"data mydata; set olddata; where name like 'A%'; run;\", \"mydata = olddata.filter(olddata['name'].like('A%'))\"),\n",
        "    (\"data mydata; set olddata; where name contains 'John'; run;\", \"mydata = olddata.filter(olddata['name'].contains('John'))\"),\n",
        "    (\"data mydata; set olddata; keep id name calculated_age; calculated_age=age+10; run;\", \"mydata = olddata.select('id', 'name').withColumn('calculated_age', olddata['age'] + 10)\"),\n",
        "    (\"data mydata; set olddata; if age>30 then age_group='Old'; else age_group='Young'; run;\", \"mydata = olddata.withColumn('age_group', when(olddata['age'] > 30, 'Old').otherwise('Young'))\"),\n",
        "    (\"data mydata; set olddata; length city $20; city=substr(address, 1, 20); run;\", \"mydata = olddata.withColumn('city', substring(olddata['address'], 1, 20))\"),\n",
        "    (\"data mydata; set olddata; drop address; run;\", \"mydata = olddata.drop('address')\"),\n",
        "    (\"proc sql; select id, name from mydata union select id, name from otherdata; quit;\", \"mydata.select('id', 'name').union(otherdata.select('id', 'name')).show()\"),\n",
        "    (\"proc sql; select id, name from mydata intersect select id, name from otherdata; quit;\", \"mydata.select('id', 'name').intersect(otherdata.select('id', 'name')).show()\"),\n",
        "    (\"proc sql; select id, name from mydata except select id, name from otherdata; quit;\", \"mydata.select('id', 'name').subtract(otherdata.select('id', 'name')).show()\"),\n",
        "    (\"data mydata; set olddata; if _n_=1 then output; run;\", \"mydata = olddata.limit(1)\"),\n",
        "    (\"data mydata; set olddata; if mod(_n_, 2)=0 then output; run;\", \"mydata = olddata.filter(olddata.rdd.zipWithIndex().map(lambda x: (x[0], x[1] % 2 == 0)).map(lambda x: x[0] if x[1] else None).filter(lambda x: x is not None).toDF(olddata.schema))\")\n",
        "\n",
        "]\n",
        "\n",
        "dataset = SimpleDataset(qa_data, tokenizer)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "0JeZ0TcXnFWJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Set model to training mode\n",
        "model.train()\n",
        "\n",
        "# Training loop (mock training)\n",
        "for batch in dataloader:\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Loss: {loss.item()}\")  # Print loss for monitoring\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(\"trained_gpt2_model\")\n",
        "tokenizer.save_pretrained(\"trained_gpt2_model\")  # Save the tokenizer as well"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1rWsAXfoKNY",
        "outputId": "2f0cf78b-63d1-4287-e3d7-34382a687842"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 6.43989896774292\n",
            "Loss: 4.31673002243042\n",
            "Loss: 3.283054828643799\n",
            "Loss: 2.2036919593811035\n",
            "Loss: 2.620326280593872\n",
            "Loss: 2.222964286804199\n",
            "Loss: 3.5895791053771973\n",
            "Loss: 2.225044012069702\n",
            "Loss: 1.8282418251037598\n",
            "Loss: 1.1461803913116455\n",
            "Loss: 1.4046096801757812\n",
            "Loss: 1.296327829360962\n",
            "Loss: 1.251974105834961\n",
            "Loss: 1.6013426780700684\n",
            "Loss: 1.0823968648910522\n",
            "Loss: 1.8188296556472778\n",
            "Loss: 1.0448658466339111\n",
            "Loss: 2.8519859313964844\n",
            "Loss: 1.5676568746566772\n",
            "Loss: 1.0785216093063354\n",
            "Loss: 0.8448755145072937\n",
            "Loss: 1.483573079109192\n",
            "Loss: 2.250091552734375\n",
            "Loss: 2.88724946975708\n",
            "Loss: 1.2571179866790771\n",
            "Loss: 1.6168956756591797\n",
            "Loss: 2.9375269412994385\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('trained_gpt2_model/tokenizer_config.json',\n",
              " 'trained_gpt2_model/special_tokens_map.json',\n",
              " 'trained_gpt2_model/vocab.json',\n",
              " 'trained_gpt2_model/merges.txt',\n",
              " 'trained_gpt2_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained(\"trained_gpt2_model\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"trained_gpt2_model\")\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUCFwiMVokOA",
        "outputId": "a8dff495-9860-4361-f5fa-aff1706d0ec5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_question(question):\n",
        "    input_text = f\"Question: {question} Answer:\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=50,\n",
        "            num_return_sequences=1,\n",
        "            no_repeat_ngram_size=2,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "    answer = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return answer.split(\"Answer:\")[-1].strip()  # Return the generated answer"
      ],
      "metadata": {
        "id": "xlG4cV0looWn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ask_question(\"proc means data=mydata; run;\"))\n",
        "# print(ask_question(\"How does AstroSynth use artificial intelligence?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5oYFYoppuKo",
        "outputId": "279d6320-3625-4576-c78b-4b4d5d1795d3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: how to give prompt\n",
        "\n",
        "# Assuming the code you provided is in a file named 'main.py' and you have already executed it in your Colab environment.\n",
        "\n",
        "# Get user input\n",
        "user_question = input(\"Enter your SAS code: \")\n",
        "\n",
        "# Call the ask_question function with the user's input\n",
        "generated_answer = ask_question(user_question)\n",
        "\n",
        "# Print the generated answer\n",
        "print(f\"Generated Spark code: {generated_answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAE7lsEHpFMv",
        "outputId": "2e9787f8-5484-46ad-f6e4-e571d45a0e86"
      },
      "execution_count": 23,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your SAS code: proc means data=mydata; run;\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Spark code: No;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q9T902EfpRTP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}